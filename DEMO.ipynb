{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.interpolate import interp1d\n",
    "import math \n",
    "import random\n",
    "import itertools\n",
    "from typing import List, Optional \n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate, optimize\n",
    "import multiprocessing\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# load the various FastSim libraries\n",
    "import Detector as Detector\n",
    "import Particle as Particle\n",
    "import Vertex as Vertex\n",
    "import lorentz_transformation as lt\n",
    "import llp_gun as llp_gun\n",
    "## depending on which fvs are used load a different specialized llp gun (llp_gun_new) (built on top of llp_gun)\n",
    "import llp_gun_new as lg\n",
    "## NOTE: the various hadronic functions in llp_gun_new must be updated with the correct path of the LLP hadronic decay \n",
    "## 4-vector files depending on the type of analysis \n",
    "\n",
    "## These hadronic functions are almost the same but were separated into different functions for ease of use with the \n",
    "## different LLP analyses - but should be very easy to update them for any new analysis that need be done\n",
    "\n",
    "\n",
    "### IMPORTANT ###\n",
    "# All the hadronic decay 4-vector files are in the rest frame of the parent LLP (see files) and the code is set-up to boost them \n",
    "# to lab frame and deal with the same\n",
    "\n",
    "# To use hadronic decay 4-vector files not in the rest frame of the parent LLP, one needs to comment/uncomment certain lines \n",
    "# in the llp_gun.py file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We give a demo of some basic functionalities i.e. creating an LLP particle or vertex manually, loading an LLP vertex from file and generating the event display. We also give a first look at the reconstruction/trigger capabilities of FastSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## LLP PARTICLE MANUALLY\n",
    "\n",
    "# Let's start with some code taken from the get_weight function itself\n",
    "\n",
    "## First, let us setup the detector by choosing a param_card\n",
    "param_card = \"param_card_CDR.txt\"\n",
    "# change this to the path to param_card on your local computer\n",
    "path_to_param_card = \"/Users/jai/Desktop/MATHUSLA_TOTAL/MATHUSLA_1/param_cards_smsrhn/\" + param_card\n",
    "\n",
    "# setup detector\n",
    "detector_benchmark = Detector.Detector(path_to_param_card)\n",
    "# lets see what the detector configuration is (might be messy, feel free to comment out)\n",
    "print(detector_benchmark.config)\n",
    "\n",
    "# clear the detector of past events, if any\n",
    "detector_benchmark.clear_detector()\n",
    "\n",
    "# choose a position for the LLP to start at - we just choose the interaction point (IP) and the sim\n",
    "# automatically uses kinematics to figure out trajectory\n",
    "position = (0,0,0)\n",
    "\n",
    "# create an LLP particle, Particle.Particle(position, 4-vector, PID)\n",
    "# play around with various 4-vectors and positions!\n",
    "four_p = (100, 0, 100, 60) # (E, px, py, pz)\n",
    "pid = 13 # let's say it is a muon (try changing the pid to an inivisble particle, say PID = 12, electron-neutrino)\n",
    "\n",
    "llp = Particle.Particle(position, four_p, pid)\n",
    "\n",
    "# feed this particle to the detector as a new (particle) event - other options include new_vertex_event which \n",
    "# feeds a vertex (i.e. an LLP with its decay products) to the detector\n",
    "detector_benchmark.new_particle_event(llp)\n",
    "\n",
    "# show/save event display (if needed) using the following (MORE information in the next few blocks)\n",
    "# setting argument show = True displays and saves\n",
    "# show = False saves but does not display\n",
    "filename = \"/Users/jai/Desktop/hello_MATHUSLA\"\n",
    "detector_benchmark.detector_display(filename, show=True)\n",
    "\n",
    "# now lets get some information about this particle after it passed through detector\n",
    "\n",
    "# get the current particle in the detector\n",
    "par = detector_benchmark.return_current_particle() \n",
    "# just print the object to get info\n",
    "print(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLP VERTEX MANUALLY\n",
    "\n",
    "# same as before\n",
    "param_card = \"param_card_CDR.txt\"\n",
    "path_to_param_card = \"/Users/jai/Desktop/MATHUSLA_TOTAL/MATHUSLA_1/param_cards_smsrhn/\" + param_card\n",
    "\n",
    "detector_benchmark = Detector.Detector(path_to_param_card)\n",
    "detector_benchmark.clear_detector()\n",
    "\n",
    "position = (0,0,0)\n",
    "four_p = (100, 0, 100, 60) # random 4-vector (might not equal sum of daughter 4-vectors, but we use it for demo anyway)\n",
    "pid = 1023\n",
    "\n",
    "# create daughter particles for the vertex \n",
    "daughter1 = Particle.Particle(position, (6, 0.2, -2.1, 3.7), 13)\n",
    "daughter2 = Particle.Particle(position, (0.7, 0, 0.3, 0.4), 211)\n",
    "daughter3 = Particle.Particle(position, (2, 0.6, 1, -0.2), 13)\n",
    "\n",
    "decay_products = [daughter1, daughter2, daughter3]\n",
    "\n",
    "# create the vertex\n",
    "vertex = Vertex.Vertex(position, four_p, pid, decay_products)\n",
    "detector_benchmark.new_vertex_event(vertex)\n",
    "\n",
    "filename = \"/Users/jai/Desktop/hello_MATHUSLA\"\n",
    "detector_benchmark.detector_display(filename, show=True)\n",
    "\n",
    "# now lets get some information about this vertex after it passed through detector\n",
    "\n",
    "# get the current vertex in the detector\n",
    "ver = detector_benchmark.return_current_vertex() \n",
    "# just print the object to get info\n",
    "print(ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# LLP VERTEX FROM FILE\n",
    "\n",
    "# same as before\n",
    "param_card = \"param_card_CDR.txt\"\n",
    "path_to_param_card = \"/Users/jai/Desktop/MATHUSLA_TOTAL/MATHUSLA_1/param_cards_smsrhn/\" + param_card\n",
    "\n",
    "detector_benchmark = Detector.Detector(path_to_param_card)\n",
    "\n",
    "##################\n",
    "# change this to the path to bb_15.txt on your local machine\n",
    "path_to_file = \"/Users/jai/Desktop/H_hadronic_decays/bb_15.txt\"\n",
    "position = (0,0,0)\n",
    "num = 2 # number of vertices you want to be read in from the given file\n",
    "\n",
    "# get vertex (in LLP rest frame)\n",
    "vertices = llp_gun.create_llp_from_file(path_to_file, position, num) # returns a list\n",
    "\n",
    "# let's choose one of these, say the first one\n",
    "vertex = vertices[0]\n",
    "\n",
    "# feed it in \n",
    "detector_benchmark.clear_detector()\n",
    "detector_benchmark.new_vertex_event(vertex)\n",
    "\n",
    "filename = \"/Users/jai/Desktop/hello_MATHUSLA\"\n",
    "print(\"Non-boosted LLP vertex\\n\")\n",
    "detector_benchmark.detector_display(filename, show=True)\n",
    "# you should notice that while their are a lot of \"Particle trajectory out of bound.\" messages printed, \n",
    "# only 3 daughter particles are visible - this is because the others go in the direction opposite/out of the display\n",
    "# frame\n",
    "\n",
    "# what if we want to boost the vertex to say some detector frame\n",
    "# we can aim the LLP at some specific starting target and boost LLP momentum to new momentum if specified as follows\n",
    "target = (0,120,70)\n",
    "p_norm = 100 # momentum LLP vertex (i.e. decay products) should be boosted to, we use the masses buit into \n",
    "#              vertex.decay_product to get the boost for each daughter\n",
    "boosted_vertex = llp_gun.align_trajectory(vertex, target, p_norm)\n",
    "\n",
    "# feed in vertex\n",
    "detector_benchmark.clear_detector()\n",
    "detector_benchmark.new_vertex_event(boosted_vertex)\n",
    "# as expected we should end up with all the daughters (there should be more than the 3 visible before!) \n",
    "# boosted forward as expected\n",
    "\n",
    "filename = \"/Users/jai/Desktop/hello_MATHUSLA\"\n",
    "print(\"Boosted LLP vertex\\n\")\n",
    "detector_benchmark.detector_display(filename, show=True)\n",
    "\n",
    "## if we look at the top right figure, it is clear that there are tracks passing through ALL the ceiling sensor planes,\n",
    "## however the top middle figure does not show the same picture, in fact, it might seem as if the tracks do not pass\n",
    "## through ALL the ceiling sensors -- THIS IS JUST AN ARTIFACT OF THE MATPLOTLIB LIBRARY NOT BEING ABLE TO PLOT 2D\n",
    "## PROJECTIONS OF 3D OBJECTS \"NICELY\", AND AS SUCH OVERLAYS/INTERSECTIONS ARE NOT EXACT ENOUGH - in this figure,\n",
    "## the detector planes always overlay the tracks\n",
    "\n",
    "## there is a work-around in the code and can be accessed by setting the argument zorder in the detector_display\n",
    "## function to zorder = 1000 (so zorder only takes TWO values, 10 (default) or 1000)\n",
    "\n",
    "detector_benchmark.detector_display(filename, show=True, zorder=1000)\n",
    "\n",
    "## as you might see, now it's the tracks that overlay the detector planes\n",
    "\n",
    "## both these views are provided as a sanity check for the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECKING IF RECONSTRUCTION/TRIGGER CRITERIA ARE PASSED\n",
    "## by now we know how to create an LLP vertex, let's learn how to check if it is actually \"detected\" or not\n",
    "\n",
    "param_card = \"param_card_CDR.txt\"\n",
    "path_to_param_card = \"/Users/jai/Desktop/MATHUSLA_TOTAL/MATHUSLA_1/param_cards_smsrhn/\" + param_card\n",
    "\n",
    "detector_benchmark = Detector.Detector(path_to_param_card)\n",
    "detector_benchmark.clear_detector()\n",
    "\n",
    "position = (0,0,0)\n",
    "pid = 1023\n",
    "four_p = (100, 0, 100, 60)\n",
    "\n",
    "daughter1 = Particle.Particle(position, (6, 0.2, -2.1, 3.7), 13)\n",
    "daughter2 = Particle.Particle(position, (0.7, 0, 0.3, 0.4), 211)\n",
    "daughter3 = Particle.Particle(position, (2, 0.6, 1, -0.2), 13)\n",
    "\n",
    "decay_products = [daughter1, daughter2, daughter3]\n",
    "\n",
    "\n",
    "vertex = Vertex.Vertex(position, four_p, pid, decay_products)\n",
    "# let's say the LLP vertex decayed at the point (0,120,70) with p_norm = 100\n",
    "target = (0,120,70)\n",
    "p_norm = 100 \n",
    "vertex = llp_gun.align_trajectory(vertex, target, p_norm)\n",
    "\n",
    "detector_benchmark.new_vertex_event(vertex)\n",
    "\n",
    "filename = \"/Users/jai/Desktop/hello_MATHUSLA\"\n",
    "detector_benchmark.detector_display(filename, show=True)\n",
    "\n",
    "# upto this point everything was same as before\n",
    "\n",
    "# how to check if LLP vertex passed DVmedium2 (DV2, see paper) recon criteria\n",
    "if detector_benchmark.vertex_reconstructed(recon_criteria=\"DVmedium2\"): # gives 0 or 1 \n",
    "    print(\"passed DV2\")\n",
    "else:\n",
    "    print(\"did not pass DV2\")\n",
    "\n",
    "# how to check if LLP vertex passed DVmedium2 (DV2, see paper) recon criteria\n",
    "if detector_benchmark.vertex_reconstructed(recon_criteria=\"DVmedium3\"): # gives 0 or 1 \n",
    "    print(\"passed DV3\")\n",
    "else:\n",
    "    print(\"did not pass DV3\")\n",
    "\n",
    "# how to check if LLP vertex passed trigger (nearest_neighbour, see paper) criteria\n",
    "# NOTE: we use detector_benchmark.event_pass_trigger(trigger_criteria) without any argument as there is only one criteria\n",
    "# and the simulation automatically uses that as default\n",
    "if detector_benchmark.event_pass_trigger():\n",
    "    print(\"passed trigger\")\n",
    "else:\n",
    "    print(\"did not pass trigger\")\n",
    "    \n",
    "# Finally we can take a product of recon and trigger to find whether LLP vertex passed both\n",
    "if detector_benchmark.vertex_reconstructed(recon_criteria=\"DVmedium2\") * detector_benchmark.event_pass_trigger():\n",
    "    print(\"passed both recon + trigger\")\n",
    "else:\n",
    "    print(\"did not pass recon or trigger or maybe both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we give an explicit demo to get the geometric efficiency using the SM + S case\n",
    "\n",
    "### First let's set-up some helper functions, which implement a lot of the functionality mentioned in Section III of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read_vectors to be used with 4-vector in the format (E, px, py, pz)\n",
    "## read_vectors_SMS to be used with 4-vectors in the format (weight, E, px, py, pz), where weight \n",
    "## is the number of real 4-vectors represented by given 4-vector (NOTE: SMS in the title, does\n",
    "## not mean it should be only used with the SM+S case)\n",
    "\n",
    "## argument \"n\" is the number of 4-vectors one needs, n = -1 reads in the entire file\n",
    "\n",
    "def read_vectors(path: str, n=-1) -> List:\n",
    "    # create llps using Higgs decay 4-vectors.\n",
    "    vectors = []\n",
    "    file = open(path, \"r\")\n",
    "    for line in tqdm.tqdm_notebook(file.readlines()[1:]):\n",
    "        # split string and convert to four-vector of ints\n",
    "        # skip over first index of elements of clean as they are serial number\n",
    "        m = list(map(float, line.strip().split(\",\")[1:]))\n",
    "        # data is for beam axis along z, our beam axis is y so update coordinates\n",
    "        m[1], m[2], m[3] = -m[1], m[3], m[2]\n",
    "        vectors.append(np.array(m))\n",
    "    if n == -1:\n",
    "        return vectors\n",
    "    else:\n",
    "        return random.sample(vectors, n)\n",
    "\n",
    "def read_vectors_SMS(path: str, n=-1) -> List:\n",
    "    # create llps using Higgs decay 4-vectors.\n",
    "    vectors = []\n",
    "    file = open(path, \"r\")\n",
    "    for line in file.readlines():\n",
    "        # split string and convert to four-vector of ints\n",
    "        m = list(map(float, line.strip().split(\",\")))\n",
    "        w = m[0] # get the weight\n",
    "        m = m[1:] # get the fv\n",
    "        # data is for beam axis along z, our beam axis is y so update coordinates\n",
    "        m[1], m[2], m[3] = -m[1], m[3], m[2]\n",
    "        vectors.append(np.array([w] + m)) # fvs are of form (w, fv) - same convention throughout code\n",
    "    if n == -1:\n",
    "        return vectors\n",
    "    else:\n",
    "        return random.sample(vectors, n) # randomly sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## These functions take in 3-vectors and return there phi and theta angles\n",
    "\n",
    "## get_theta is used to check if an LLP (4-vector) passes through the detector or not\n",
    "\n",
    "## deal_with_phi takes advantage of rotational symmetry about the beam axis to randomly \n",
    "## choose a phi\n",
    "\n",
    "# beam axis is y-axis\n",
    "# theta is angle to y-axis i.e. arccos(y/r)\n",
    "# phi is angle to x in x-z plane i.e arctan(x/z) \n",
    "\n",
    "def get_phi(u) -> float:# u is a three-vector \n",
    "    phi = np.arctan2(u[0], u[2]) # (x, z)\n",
    "    return phi \n",
    "\n",
    "def get_theta(u) -> float:\n",
    "    return np.arccos(u[1]/np.linalg.norm(u)) # (y/r)\n",
    "\n",
    "def deal_with_phi(four_p: List[float], phi_min: float, phi_max: float) -> List[float]:\n",
    "    \n",
    "    curr_phi = get_phi(four_p[1:])\n",
    "    new_phi = random.uniform(phi_min, phi_max)\n",
    "    p_rot = lt.rotation(four_p[1:], np.array([0,1,0]), new_phi - curr_phi)\n",
    "    new_4p = np.array([four_p[0], p_rot[0], p_rot[1], p_rot[2]])\n",
    "\n",
    "    return new_4p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAIN FUNCTION\n",
    "\n",
    "## this function takes in an LLP 4-vector and if it passes through the detector, returns\n",
    "## a weight i.e. probability of decay in the detector (according to formula mentioned in paper),\n",
    "## decay position (w.r.t. the exponential CDF of the probability) and its boost. Returns None is LLP 4-vector\n",
    "## does not pass through detector.\n",
    "\n",
    "## NOTE: a lot of the components of this function can be used by themselves as separate functions\n",
    "## if need be depending on the context\n",
    "\n",
    "# ctau is lifetime, might be input by hand or given by reading in a file\n",
    "# detector_benchmark is a Detector object, which we show how to initialize later\n",
    "def get_weight(four_p: List[float], mass: float, ctau: float, detector_benchmark: Detector.Detector) -> Optional[tuple]:\n",
    "    \n",
    "    ## first we check if 4-vector passes through the detector and if it does, obtain its boundary hit coordinates i.e.\n",
    "    ## entry (L1) and exit points (L2)\n",
    "    \n",
    "    # clear the detector of past events, if any\n",
    "    detector_benchmark.clear_detector()\n",
    "    # choose a position for the LLP to start at - we just choose the interaction point (IP) and the sim\n",
    "    # automatically uses kinematics to figure out trajectory\n",
    "    position = (0,0,0)\n",
    "    # create an LLP particle, Particle.Particle(position, 4-vector, PID) - choose a random PID\n",
    "    llp = Particle.Particle(position, four_p, 13)\n",
    "    # feed this particle to the detector as a new (particle) event - other options include new_vertex_event which \n",
    "    # feeds a vertex (i.e. an LLP with its decay products) to the detector\n",
    "    detector_benchmark.new_particle_event(llp)\n",
    "\n",
    "    # set up a list to collect boundary hit point coordinates\n",
    "    L1L2 = []\n",
    "    \n",
    "    # this list is a short-hand way of coordinates of the detector's boundary planes\n",
    "    decay_vol_boundaries=['x-','x+','y-','y+','z-','z+']\n",
    "    \n",
    "    # if LLP passes through the detector\n",
    "    if (detector_benchmark.track_is_in_decay_volume()):\n",
    "        \n",
    "        # get all the sensor layer hits in within the decay volume\n",
    "        current_decay_volume_intersections = detector_benchmark.return_current_particle().decay_volume_hits\n",
    "\n",
    "        # collect all the boundary hit objects\n",
    "        decay_vol_boundaries_hits=[]\n",
    "        \n",
    "        # going through each of the boundary planes, check if there is a hit and collect it\n",
    "        for i in decay_vol_boundaries:\n",
    "            if current_decay_volume_intersections[i][0]:\n",
    "                decay_vol_boundaries_hits.append(current_decay_volume_intersections[i][1])\n",
    "\n",
    "        # another sanity check, there should be 2 hits, entry and exit\n",
    "        if (len(decay_vol_boundaries_hits) == 2):\n",
    "            # now convert list of hit coordinates into distance from the origin/IP\n",
    "            L1L2 = [math.sqrt(item[0]**2 + item[1]**2 + item[2]**2) for item in decay_vol_boundaries_hits]\n",
    "            L1L2.sort()\n",
    "            # L1 is distance of entry point to IP\n",
    "            # L2 is distance of exit point to IP\n",
    "            L1,L2 = L1L2\n",
    "            # sort the decay_vol_boundaries_hits so that the first (second) entry corresponds to coordinates of L1 (L2)\n",
    "            decay_vol_boundaries_hits.sort(key=lambda x:math.sqrt(x[0]**2 + x[1]**2 + x[2]**2))\n",
    "            \n",
    "            # get the boost\n",
    "            b = np.linalg.norm(four_p[1:])/mass \n",
    "            \n",
    "            # now using random variable PDF inversion (using uniform distribution) get an exponential distribution for \n",
    "            # decay probability between L1 and L2\n",
    "            unif = random.uniform(1-np.exp(-L1/(b*ctau)), 1-np.exp(-L2/(b*ctau)))\n",
    "            exp = -b*ctau*np.log(1-unif) # use pdf inversion to get exponential distribution\n",
    "            # explicitly get the decay position by multiply unit vector along L1 with the chosen norm from the exp distribution\n",
    "            decay_position = np.array(decay_vol_boundaries_hits[0])/L1 * exp\n",
    "            \n",
    "            # get the weight i.e. probability of decay within the detector volume\n",
    "            weight = np.exp(-L1/(b*ctau)) - np.exp(-L2/(b*ctau))\n",
    "\n",
    "            return weight, decay_position, b\n",
    "        \n",
    "        # or return None if LLP does not pass through the detector\n",
    "        else: \n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting the above functions to use (might take a while to fimish running!)\n",
    "\n",
    "NOTE: Once again, a lot of the parts of the block below can be used as independent functions by themselves, we just give an example of how we used the entire code to get data for the SM+S case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# choose a mass for the LLP (in GeV)\n",
    "m = 1.0\n",
    "\n",
    "# choose a param card - we choose the default CDR geometry\n",
    "card = \"param_card_CDR.txt\"\n",
    "\n",
    "# setup a list of possible coupling values to be probed in the sim\n",
    "thetas = 10**(np.linspace(-7,-1,num=121))\n",
    "    \n",
    "## now we setup the pipeline which takes into account all possible decays and their\n",
    "## branching ratios\n",
    "      \n",
    "# use decay product masses as threholds for various types of decays\n",
    "m_e = 0.511e-3 \n",
    "m_mu = 0.1056 \n",
    "m_pi = 0.13957039 \n",
    "m_pi0 = 0.1349768 \n",
    "\n",
    "# make a dictionary of the mass ranges and possible decays \n",
    "# ranges are based on Br figure from the source paper + make sure that the decay file for the mass exists\n",
    "decays = {(2*m_e,2*m_mu):{\"e\":\"leptonic2body\"}, (2*m_mu,2*m_pi0):{\"mu\":\"leptonic2body\"}, \n",
    "          (2*m_pi0,0.7):{\"mu\":\"leptonic2body\",\"pi\":\"leptonic2body\"}, \n",
    "          (0.7,0.99):{\"mu\":\"leptonic2body\", \"hadrons0.7to0.98gev\":\"hadronic\"}, \n",
    "          (1,2):{\"mu\":\"leptonic2body\", \"hadrons1to2gev\":\"hadronic\"},(2, 3.6):{\"g\":\"hadronic\", \"s\":\"hadronic\", \"mu\":\"leptonic2body\"}, (3.6, 3.8):{\"g\":\"hadronic\", \"s\":\"hadronic\", \"tau\":\"hadronic\", \"mu\":\"leptonic2body\"}, (3.8, 5):{\"g\":\"hadronic\", \"s\":\"hadronic\", \"c\":\"hadronic\", \"tau\":\"hadronic\", \"mu\":\"leptonic2body\"}}\n",
    "\n",
    "# read in digitized data i.e. branching ratios and lifetime (in metres) of the LLP\n",
    "br = {}\n",
    "# change path to local machine\n",
    "path = \"/Users/jai/Desktop/MATHUSLA_TOTAL/SM+S/\"\n",
    "fnames = [f for f in os.listdir(path) if isfile(join(path, f))]\n",
    "for fname in fnames:\n",
    "    if fname != \".DS_Store\": # this line is specifically for MacOS \n",
    "        br[fname] = np.loadtxt(path + fname, delimiter=',')\n",
    "        br[fname] = interpolate.interp1d(br[fname][:,0], br[fname][:,1],fill_value=\"extrapolate\")\n",
    "\n",
    "# now we go through the all possible decays and choose the possible decays for the given mass, m\n",
    "possible_decays = None\n",
    "for mass_range in decays:\n",
    "    if mass_range[0] <= m < mass_range[1]: # if condition should always be satisfied for atleast one mass range\n",
    "        possible_decays = decays[mass_range]\n",
    "\n",
    "if len(possible_decays) == 1: # i.e. e or mu 100% Br\n",
    "    possible_brs = {list(possible_decays.keys())[0]:1}\n",
    "elif 2*m_pi0 < m < 2*m_pi:\n",
    "    brmu = float(br[\"Smu.csv\"](m))\n",
    "    possible_brs = {\"mu\":brmu, \"pi\":1-brmu}\n",
    "elif \"hadrons0.7to0.98gev\" in possible_decays:\n",
    "    brmu = float(br[\"Smu.csv\"](m))\n",
    "    possible_brs = {\"mu\": brmu, \"hadrons0.7to0.98gev\": 1-brmu}\n",
    "elif \"hadrons1to2gev\" in possible_decays:\n",
    "    brmu = float(br[\"Smu.csv\"](m))\n",
    "    possible_brs = {\"mu\": brmu, \"hadrons1to2gev\": 1-brmu}\n",
    "else:\n",
    "    possible_brs = {}\n",
    "    for name in br:\n",
    "        if name[1:-4] in possible_decays: # if condition should always be satisfied\n",
    "            possible_brs[name[1:-4]] = float(br[name](m))\n",
    "    # renormalize the Br to 1 at each mass point (as we ignore certain very low-chance decays)\n",
    "    factor = np.sum(list(possible_brs.values()))\n",
    "    for key in possible_brs:\n",
    "        possible_brs[key] = possible_brs[key]/factor \n",
    "\n",
    "## now we have a dictionary, possible_brs whose keys are the possible decay name and values are\n",
    "## corresponding branching ratios\n",
    "\n",
    "################## now preliminaries are done ##################\n",
    "\n",
    "# read in all the LLP 4-vectors from the SM+S LLP file (need all as the sum of the 4-vector\n",
    "# weights adds up to xsec * lumi i.e. the actual number of SM+S generated LLPs generated at for e.g. CERN)\n",
    "\n",
    "# change path to local machine i.e. where you store \"SMS_LLPweight4vectorBmesonlist_mS_1.0.csv\"\n",
    "fv_path = \"/Users/jai/Desktop/All_SMS_LLPweight4vectors_from_B\"\n",
    "fv_name = \"SMS_LLPweight4vectorBmesonlist_mS_\" + str(m) + \".csv\"\n",
    "\n",
    "# use the read_vectors_SMS file to read in, as format of 4-vectors is (weight, E, px, py, pz)\n",
    "vectors = read_vectors_SMS(os.path.join(fv_path,fv_name), -1) # 4-vectors from B parents\n",
    "# NOTE: for other types of LLP models such as RHN_Ui might have to read in 4-vectors from other sources \n",
    "# too like D mesons, W-,Z-bosons etc.\n",
    "\n",
    "# finally, note length of read-in 4-vector list as we use this to iterate through this list later\n",
    "num_iter = len(vectors)\n",
    "\n",
    "# finally run the simulation - setup the detector by giving it the path to the chosen param_card\n",
    "# change path to local machine\n",
    "detector_benchmark = Detector.Detector(\"/Users/jai/Desktop/MATHUSLA_TOTAL/MATHUSLA_1/param_cards_smsrhn/\" + card)\n",
    "\n",
    "# find max min angles OF THE DECAY VOLUME (note its not the detector volume!)\n",
    "x = np.array([detector_benchmark.config.decay_x_min, detector_benchmark.config.decay_x_max])\n",
    "y = np.array([detector_benchmark.config.decay_y_min, detector_benchmark.config.decay_y_max])\n",
    "z = np.array([detector_benchmark.config.decay_z_min, detector_benchmark.config.decay_z_max])\n",
    "\n",
    "corners = np.array(np.meshgrid(x, y, z)).T.reshape(-1,3)\n",
    "points = corners.copy()\n",
    "\n",
    "detector_theta = []\n",
    "detector_phi = []\n",
    "\n",
    "# for efficiency, randomly generate 100 points lying in/on the detector and take min,max angles from these\n",
    "# -- ends up giving the (almost) actual min, max (using Central Limit Theorem)\n",
    "for j in itertools.product(corners, corners):\n",
    "    for k in range(100):\n",
    "        u = random.uniform(0,1)\n",
    "        new = u * j[0] + (1-u) * j[1]\n",
    "        detector_theta.append(get_theta(new))\n",
    "        detector_phi.append(get_phi(new))\n",
    "\n",
    "theta_min, theta_max = min(detector_theta), max(detector_theta)\n",
    "phi_min, phi_max = min(detector_phi), max(detector_phi)\n",
    "\n",
    "# now we have angle ranges for MATHUSLA and can compare LLP 4-vectors (with starting point being the IP)\n",
    "# with the same to check if they pass through the detector decay volume\n",
    "\n",
    "# iterate through each possible coupling we want to probe\n",
    "for index in tqdm(range(len(thetas))): \n",
    "    print(\"starting new theta value\")\n",
    "    theta = thetas[index]\n",
    "\n",
    "    # dictionary to collect geometric efficiency under different criteria\n",
    "    eff = {\"perfect\":0,\"DVmedium2\":0,'DVmedium3':0,\"DVmedium2loose1\":0,\"DVtight2\":0,\n",
    "          'DVsupertight2':0,'DVtight1medium1':0,'DVtight1loose1':0,'DVtight3':0,\n",
    "          'DVtight2medium1':0,'DVtight1medium2':0,'DVtight1loose2':0}\n",
    "\n",
    "    # official c = 299,792,458 m/s\n",
    "    c = 299792458\n",
    "    \n",
    "    # read in ctau corresponding to our chosen mass, m, from a file\n",
    "    # NOTE: there are two files we read in from depending on the mass, thus the if else block\n",
    "    if m in [0.03, 0.0774597, 0.2, 0.212]:\n",
    "        ctau = c * br[\"Slife_old.csv\"](m) * (theta**(-2)) * 10**(-12)\n",
    "    else:\n",
    "        # ctau = c(m/s) * tau(s) * coupling factor\n",
    "        ctau = c * br[\"Slife_new.csv\"](m) * (theta**(-2))\n",
    "\n",
    "    ################## actual simulation ################ \n",
    "    # iterate through the LLP 4-vectors\n",
    "    for k in tqdm(range(num_iter)): \n",
    "        # first entry is weight\n",
    "        four_pw = vectors[k] # fv[0] is weight \n",
    "        # reweigh the weight depending on the coupling (MODEL SPECIFIC!)\n",
    "        # reweigh by sin_theta^2 ~ theta^2 in our case, as the Br depends on theta\n",
    "        w = four_pw[0] * theta**2 \n",
    "        # keep track of actual 4-vector\n",
    "        four_p = four_pw[1:]\n",
    "        # get the LLP theta and phi angles \n",
    "        llp_theta = get_theta(four_p[1:])\n",
    "        llp_phi = get_phi(four_p[1:])\n",
    "        # check if LLP passes theta (equivalently eta) range of MATHUSLA i.e. it has chance of passing through\n",
    "        ## (NOTE: while theta check should ensure that LLP SHOULD pass through, sometimes it still might not\n",
    "        #       due on numerical precision etc - all these sanity checks are built in at every stage)\n",
    "        if (llp_theta > theta_min) and (llp_theta < theta_max):\n",
    "            # if it does, randomly rotate the phi of the LLP 4-vector\n",
    "            four_p_rot = deal_with_phi(four_p, phi_min, phi_max)\n",
    "            # use new 4-vector, lifetime of LLP, and the detector to generate\n",
    "            # weight, decay position, boost of the LLP\n",
    "            pack = get_weight(four_p_rot, m, ctau, detector_benchmark) # returns weight, decay_position, boost           \n",
    "            \n",
    "            # if get_weight does not return None i.e. LLP enter and exits detector (and there is no numerical precision issue etc.)\n",
    "            if pack is not None:\n",
    "                # for perfect decay, don't care about detection, just add (probabilty of decay * weight) to efficiency dictionary\n",
    "                # this is why dont have any condition on decay such as reconstructed() etc.\n",
    "                eff[\"perfect\"] += pack[0] * w \n",
    "\n",
    "                ## determine if decay detected w.r.t. criterions or not\n",
    "                \n",
    "                # once again, clear the detector of previous events (if any)\n",
    "                detector_benchmark.clear_detector()\n",
    "                \n",
    "                # randomly chose a decay based on branching ratio using possible_brs dictionary\n",
    "                chosen_decay = random.choices(list(possible_brs.keys()), list(possible_brs.values()), k=1)[0]\n",
    "\n",
    "                ## now get llp from the LLP gun depending on chosen decay\n",
    "                ## NOTE: the last argument (i.e. decay_product) to lg.get_llp(type of decay, mass of LLP, decay position, boost, decay_product) \n",
    "                ## changes based on type of decay needed as follows:\n",
    "                \n",
    "                ## two-body decay to particle/anti-particle pair: \n",
    "                ## the last argument is list of PIDs of decay products e.g. [11,-11]\n",
    "                \n",
    "                ## three-body decay to particle/anti-particle/(anti-)neutrino:\n",
    "                ## the last argument is list of PIDs of decay products e.g. [11,-11,12]\n",
    "                \n",
    "                ## hadronic decay:\n",
    "                ## either empty for RHN or the type of hadronic decay (e.g. \"ss\") for SM+S\n",
    "                \n",
    "                ## change paths in llp_gun_new.py to those on the local machine (see llp_gun_new.py)\n",
    "                \n",
    "                if chosen_decay == \"e\":\n",
    "                    # should be [11,-11] below but we \"cut corners\" and just feed in [11,11] as only the fact\n",
    "                    # that a particle is charged or not matters, not the actual value of the charge\n",
    "                    llp = lg.get_llp(\"leptonic2body\", m, pack[1], pack[2], [11,11])\n",
    "\n",
    "                elif chosen_decay == \"mu\": \n",
    "                    llp = lg.get_llp(\"leptonic2body\", m, pack[1], pack[2], [13,13])\n",
    "\n",
    "                elif chosen_decay == \"pi\": # pi means pi+-\n",
    "                    if 2*m_pi0 <= m < 2*m_pi:\n",
    "                        llp = None\n",
    "                    else:\n",
    "                        x = random.choices([\"+\",\"0\"], [2/3,1/3], k=1)[0]\n",
    "                        if x == \"+\": \n",
    "                            llp = lg.get_llp(\"leptonic2body\", m, pack[1], pack[2], [211,211])\n",
    "\n",
    "                        else:\n",
    "                            llp = None\n",
    "\n",
    "                elif chosen_decay == \"hadrons0.7to0.98gev\": \n",
    "                    llp = lg.get_llp(\"hadronic_SMS\", m, pack[1], pack[2],\"hadrons0.7to0.98gev\")\n",
    "                    # hadronic_SMS because we are doing the SM+S case\n",
    "                    # change to hadronic_RHN_Ui or hadronic_HXX depending on the LLP case\n",
    "                    # please look at the llp_gun_new files for function inputs depending on the LLP case\n",
    "\n",
    "                elif chosen_decay == \"hadrons1to2gev\": \n",
    "                    llp = lg.get_llp(\"hadronic_SMS\", m, pack[1], pack[2],\"hadrons1to2gev\")\n",
    "\n",
    "                elif chosen_decay == \"g\": \n",
    "                    llp = lg.get_llp(\"hadronic_SMS\", m, pack[1], pack[2],\"gg\")\n",
    "\n",
    "                elif chosen_decay == \"c\":\n",
    "                    llp = lg.get_llp(\"hadronic_SMS\", m, pack[1], pack[2],\"cc\")\n",
    "\n",
    "                elif chosen_decay == \"s\":\n",
    "                    llp = lg.get_llp(\"hadronic_SMS\", m, pack[1], pack[2],\"ss\")\n",
    "\n",
    "                else: # tau-tau\n",
    "                    llp = lg.get_llp(\"hadronic_SMS\", m, pack[1], pack[2],\"tautau\")\n",
    "\n",
    "                # make sure LLP is not None i.e. not an invisible decay\n",
    "                if llp is not None:\n",
    "                    detector_benchmark.new_vertex_event(llp)\n",
    "                    \n",
    "                    # show/save event display (if needed) using the following (uncomment to see)\n",
    "                    # setting argument show = True displays and saves\n",
    "                    # show = False saves but does not display\n",
    "#                     filename = \"/Users/jai/Desktop/figs/CDR_benchmark_vertex_LLPgun_\" + str(k)\n",
    "#                     detector_benchmark.detector_display(filename, show=True)\n",
    "                    \n",
    "                    # this section below is for when reconstruction matters (i.e. drop the perfect assumption)\n",
    "                    for typ in eff: # typ is reconstruction criteria which form the keys of eff dictionary\n",
    "                        if typ != \"perfect\":\n",
    "                            # detector_benchmark.vertex_reconstructed(recon_criteria=typ) is 1 \n",
    "                            # if LLP vertex reconstructed using given critera, 0 otherwise \n",
    "                            \n",
    "                            # detector_benchmark.event_pass_trigger(trigger_criteria) is 1 \n",
    "                            # if LLP vertex passes trigger criteria, 0 otherwise \n",
    "                            # NOTE: we use detector_benchmark.event_pass_trigger() without any argument as there is only one criteria\n",
    "                            # and the simulation automatically uses that as default\n",
    "                            \n",
    "                            # if recon only is needed, delete/comment out the pass_trigger function\n",
    "                            eff[typ] += pack[0] * w * detector_benchmark.vertex_reconstructed(recon_criteria=typ) * detector_benchmark.event_pass_trigger()\n",
    "\n",
    "\n",
    "    ##################################\n",
    "    # using efficiencies to get N_obs i.e. number of LLPs observed \n",
    "    \n",
    "    # N_obs(criteria) = xsec * lumi * eff(criteria) * (phi_min - phi_max)/(2pi)\n",
    "    # last factor needed to correct for random phi rotation about beam-axis\n",
    "    \n",
    "    eps_phi = (phi_max-phi_min)/(2*np.pi)\n",
    "    \n",
    "    N_obs = {\"perfect\":0,\"DVmedium2\":0,'DVmedium3':0,\"DVmedium2loose1\":0,\"DVtight2\":0,\n",
    "          'DVsupertight2':0,'DVtight1medium1':0,'DVtight1loose1':0,'DVtight3':0,\n",
    "          'DVtight2medium1':0,'DVtight1medium2':0,'DVtight1loose2':0}\n",
    "\n",
    "    for typ in N_obs:\n",
    "        N_obs[typ] = eff[typ] * eps_phi \n",
    "        \n",
    "    # let's see if the sim worked\n",
    "    print(\"mass:\", m)\n",
    "    print(\"coupling:\", theta, \"\\n\")\n",
    "    for typ in N_obs:\n",
    "        print(\"N_obs for\", typ, \":\", N_obs[typ], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting hadronic decay 4-vectors into Fastim format\n",
    "\n",
    "While we have provided links to repositories containing the hadronic decay products required for various LLP analyses, the FastSim takes them as input in a specific format (for e.g. look at file \"bb_15.txt\" or \"SMS_LLPweight4vectorBmesonlist_mS_1.0.csv\"). Here we demo the script to convert the given files into such a format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from script import *\n",
    "\n",
    "# we take in file bb_15 but in the geant (given) format and convert it into the format used in the section \"VERTEX FROM FILE\" \n",
    "\n",
    "# first argument is where to save output, second argument is where to read in the file to be converted\n",
    "# change paths as needed\n",
    "write_hadrons_for_fastsim(\"/Users/jai/Desktop/temp.txt\", \"/Users/jai/Desktop/final_data_aug_5/geant_decays/H_hadronic_decays_geant/bb_15.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
